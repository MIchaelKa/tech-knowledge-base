
# Parent

[[Reasoning]]

# Overview

Training Large Language Models to Reason in a Continuous Latent Space
- https://arxiv.org/abs/2412.06769

Paper Review
- https://andlukyane.com/blog/paper-review-coconut

COCONUT: Учим LLM думать не словами, а эмбеддингами (by Meta)
- https://t.me/abstractDL/311
- Обучение жрёт много компьюта и памяти, т.к. по сути это рекуррентная модель, через которую нужно N раз пропустить градиенты насквозь.

Training Large Language Models to Reason in a Continuous Latent Space
- https://t.me/gonzo_ML/3567
- Coconut (**C**hain **O**f **CON**tin**U**ous **T**hought)
- Последнее скрытое состояние можно не декодировать в токен, а сразу подавать его на вход декодера в авторегрессионном процессе генерации как эмбеддинг для следующего шага.
- [[Byte Latent Transformer (BLT)]]
- язык оптимизирован для коммуникации, а не для думания.
- LLM переключается между двумя режимами: языковым (language mode) и латентным (latent mode).
- Начало и окончание латентного режима обрамляется токенами `<bot>` и `<eot>`.
	- По-прежнему нужно декодировать каждый токен даже в latent mode чтобы понять нужно ли переключить режим?
	- для `<eot>` рассматриваются две стратегии
		- обучить бинарный классификатор, решающий по эмбеддингу, когда надо переключаться
		- добивать паддингом латентные размышления до фиксированной длины.
- латентных мысли
	- две латентных мысли (c=2) на каждый шаг ризонинга
- Тест датасеты
	- математический ризонинг - GSM8k
	- логический ризонинг - ProntoQA, ProsQA
- Сравнение
	- iCoT, implicit CoT
	- Pause token
- BFS
	- Латентный ризонинг можно интерпретировать как поиск по дереву, если опираться на интуицию, что непрерывные мысли могут содержать более одного шага рассуждения.
	- MCTS
	- И вообще выглядит, что обучили не непрерывный CoT, а непрерывный ToT
- References
	- LCM
	- iCoT
	- ToT


chatgpt eng
- https://chatgpt.com/c/68df922c-8878-832f-a1ed-65ad3b8b1f27

chatgpt rus
- https://chatgpt.com/c/68df92ad-f480-8327-9f9e-ebb01f728cfe
- breadth-first search (BFS) в латентном пространстве
- Улучшения на задачах с откатами (backtracking)
  

Вопросы
- Я правильно понимаю что токены bot и cot присутствуют в обучении всегда, на всех этапах, и в начале просто показывают начало и конец рассуждений в пространстве токенов.
- Далее мы для первых k токенов рассуждений мы подменяем эмбеддинги полученные из токенов на эмбеддинги с скрытого слоя.
- Лосс при этом не учитывает то что происходит на позиции в этих замененных токенах, то есть в теории там могут предсказываться абсолютный мусор в качестве токенов но нас это устраивает
- Но что в итоге дает сигнал к рассуждению у модели в латентных токенах если лосс не учитывает эти позиции?

Ответ
- curriculum learning
- Это по сути «постепенная дистилляция»: модель сначала видит весь CoT как текст, потом её всё больше и больше заставляют «думать» в латентном пространстве вместо текста.
- Хотя мы маскируем loss на «латентных токенах», их скрытые состояния всё равно участвуют в вычислениях для следующих шагов

Coconut vs. RNN
- Поэтому это похоже на то как работают реккурентные сети?
- backpropagation сквозь время (BPTT)
- Coconut — это что-то среднее между:
	- CoT (цепочка в токенах, loss на каждом токене)
	- RNN (цепочка скрытых состояний, loss может быть только на конце)

Вопрос
- "Состояние оптимизатора сбрасывается между отдельными этапами."
- Что является этапом и зачем сбрасывать состояние между этапами?

Ответ
- Это как раз про curriculum learning
- Stage 0 (базовый): модель учится обычному CoT — всё рассуждение в токенах (loss на каждом шаге рассуждений).
- Stage 1: первые 1 токен рассуждения заменяется на latent embedding, остальные шаги остаются токенными.

Про состояние оптимизатора
- Adam хранит внутренние моменты (running averages).
- Vanilla SGD - нет состояния