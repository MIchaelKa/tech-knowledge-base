
# TODO

InternLM
[[Mamba]]

langchain

MMLU
[[RoPE]]
p-tuning

**Done**

# External


Notion
- https://www.notion.so/LLM-36725aa99601409291ae54c42fb0c4b1


# Термины

**ICL**
in-context learning

# Posts


Как выжать максимум из LLM?
- https://t.me/bogdanisssimo/288

Ссылки
- [[RAG]]
- kNN few-shot
- Chain-of-Thought (CoT)

Ensemble choice shuffle
- Техника которая работает когда нужно выбрать один вариант из нескольких предоставленных.
- MMBench

# Контекст

Короткий комментарий про длинные контексты.
- https://t.me/gonzo_ML/3408
- В общем, по-прежнему не работает тема "запихну всё в один большой промпт". Ну как не работает, технически работает, но продуктово...

Сколько длина контекста у ChatGPT4o?
- Сколько теконов?
- Сколько это в листах А4?
- https://chatgpt.com/c/c529ecbd-0639-4a25-8e7f-766a0bf16976

Q
- Как задавать вопросы по книге?
- Насколько важно поместить всю книгу в контекст?

# Overview

Temperature
- https://chatgpt.com/c/679b97ff-9d50-8000-9566-3b83e09f66b1
- [[Temperature]]
- https://platform.openai.com/docs/api-reference/chat/create

Structured Outputs
- https://docs.vllm.ai/en/latest/features/structured_outputs.html
- guided decoding
- развернутые ответ и COT vs. answer in single word
	- [[OpenAI o1]]
- ChatML

Predicted Outputs
- https://t.me/seeallochnaya/1964
- https://platform.openai.com/docs/guides/predicted-outputs
- in canvas
	- predicted output openai is enabled in canvas?

Thinking
- Thinking
- [[OpenAI o1]]
- [[DeepSeek]]
