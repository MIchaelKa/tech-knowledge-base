
DeepSeek 2.5
- https://t.me/ai_newz/3529

GH
- https://github.com/deepseek-ai

# DeepSeek-R1

[[Reasoning]]

DeepSeek
- искать разборы в gonzo_ML

A shocking Chinese AI advancement called DeepSeek is sending US stocks plunging
- https://edition.cnn.com/2025/01/27/tech/deepseek-stocks-ai-china/index.html
- R1


Про магию DeepSeek, RL и GRPO
- https://t.me/gonzo_ML/3289
- https://t.me/buckwheat_thoughts/104
- RLHF в виде PPO
	- PPO — это штука сложная, нестабильная и требовательная к качеству ревард модели
- DPO
	- ?
	- Это, по сути, стало стандартом для преференс-тюнинга моделей.
- GRPO
	- DeepSeek Math
- сфт колдстарт


The Illustrated DeepSeek-R1
- https://t.me/gonzo_ML/3266
- https://newsletter.languagemodels.co/p/the-illustrated-deepseek-r1
- thinking tokens
- CoT
- reasoning tasks
	- reasoning-related benchmarks
	- what the example of the task what do not required reasoning?
- R1-Zero
	- Large-Scale Reasoning-Oriented RL
	- No labeled SFT training set
	- Automatic Verification of a Reasoning Problem
		- Code problems
		- Other examples?
- Arch
	- [[Mixture of Experts (MoE)]]


Толока
- R1 is not on par with o1, and the difference is qualitative, not quantitative
	- https://toloka.ai/blog/r1-is-not-on-par-with-o1-and-the-difference-is-qualitative-not-quantitative/
- External
	- https://t.me/boris_again/3084
		- [[Confidence Interval]]
	- https://t.me/seeallochnaya/2405
- Тесты на задачах из длинного хвоста


# VLM

[[VLM]]

Notion
- https://www.notion.so/VLM-df9b285137bc4c55b398531cfb4ca701#663f613d0fe64535be871e03b51bde6f

DeepSeek-VL2
- https://github.com/deepseek-ai/DeepSeek-VL2
- https://huggingface.co/deepseek-ai/deepseek-vl2-tiny
