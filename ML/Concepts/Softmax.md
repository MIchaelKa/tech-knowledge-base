
# Links

[[Cross Entropy Loss (CEL)]]

# Overview

softmax
- https://en.wikipedia.org/wiki/Softmax_function

softmax vs. sigmoid
- https://stats.stackexchange.com/questions/233658/softmax-vs-sigmoid-function-in-logistic-classifier
- softmax vs. sigmoid for one class classification in the last layer
- softmax gives the same probabilities when number of classes K = 2


Softmax classifier
- https://cs231n.github.io/linear-classify/#softmax
- Information theory view
	- [[Entropy]]
- Probabilistic interpretation
	- [[MLE]]

Softmax
- Зачем нужно использовать экспоненту, почему просто не нормализовать поделив каждые скор на сумму все скоров?
- https://chatgpt.com/c/6178dc8e-03af-41d0-b454-b148d283a27b
- 