
https://machinelearningmastery.com/exploding-gradients-in-neural-networks/

The model loss goes to NaN during training.