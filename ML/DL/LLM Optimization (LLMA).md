
LLM Accelerating (LLMA)
# External

GPU Optimization Workshop
- https://www.notion.so/GPU-Optimization-Workshop-7a38ac2c0d7548ceb9342a215404dfc1

Mastering LLM Techniques: Inference Optimization
- https://developer.nvidia.com/blog/mastering-llm-techniques-inference-optimization/

# Links

[[FLOPS]]
[[GPU Memory]]
[[FlashAttention]]
[[KV-Cache]]

