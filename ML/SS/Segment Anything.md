
SAM

# Внешние ссылки

**Paper**
Segment Anything
https://arxiv.org/abs/2304.02643

**Official**
https://segment-anything.com/

Introducing Segment Anything: Working toward the first foundation model for image segmentation
https://ai.meta.com/blog/segment-anything-foundation-model-image-segmentation/

**TG**
https://t.me/ai_newz/1846


# Сводка

**Основные моменты**
Foundation model for image segmentation
GPT-3 moment for segmentation
Promptable segmentation

**Количество параметров**
Image Encoder - 632M параметров.
Encoder запросов и decoder масок - 4M параметров.

**Оценка**

**Данные для тренировки**
SA-1B Dataset
1 млрд масок на 11 млн изображений
https://ai.meta.com/datasets/segment-anything/

# Ссылки

[[Zero-Shot Learning (ZSL)]]
zero-shot transfer

# Обзор

**Foundation model**
*foundation model for image segmentation: a **promptable** model that is trained on diverse data and that can adapt to specific tasks, analogous to how prompting is used in natural language processing models.*

**Prompts**
clicks, boxes, text, and so on

**Speed and annotations**
*model needs to run in real time on a CPU in a web browser to allow our annotators to use SAM interactively*


# Данные


*The data was collected using SAM.*
Как это работает когда модель ошибается?
[[Pseudo Labeling]]




# Архитектура


# Обучение


# Оценка


# Термины


# Вопросы

