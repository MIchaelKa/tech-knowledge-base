
# Внешние ссылки

**Paper**
MMBench: Is Your Multi-modal Model an All-around Player?
https://arxiv.org/abs/2307.06281

**Official**
https://mmbench.opencompass.org.cn/home

**GH**
https://github.com/open-compass/mmbench

**VLMEvalKit**
https://github.com/open-compass/VLMEvalKit
[[_DNB_VLM_Eval]]

# Сводка


**Основные моменты**
Использование ChatGPT
CircularEval

**Формат** 

**Метрики**

**Размер**


# Ссылки

>Traditional benchmarks like [[VQAv2]] or COCO Caption


# Термины


# Вопросы


# Обзор

**Использование ChatGPT**
Используют ChatGPT для того чтобы соотнести аутпут LLM с одним из доступных вариантов ответа
ChatGPT vs. gpt-3.5-turbo-0613

**CircularEval**
Прокрутка вариантов ответов при каждом прогоне.
При таком подходе средняя точность моделей падает на 10-20%

# Данные


# Архитектура


# Обучение


# Оценка

