
Moved
https://www.notion.so/cs231n-f5cdcd5f61704e05b52f3f1c56641385

Convolutional Neural Networks for Visual Recognition

# External Links

Main link
[http://cs231n.stanford.edu/](http://cs231n.stanford.edu/)

Winter 2016
[http://cs231n.stanford.edu/2016/](http://cs231n.stanford.edu/2016/)
[https://www.youtube.com/playlist?list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC](https://www.youtube.com/playlist?list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC)

**2017**
[https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv](https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv)


# 5. Training Neural Networks

Lecture 5
2016 video
[https://youtu.be/gYpoJMlgyXA](https://youtu.be/gYpoJMlgyXA)

https://cs231n.github.io/neural-networks-2
https://cs231n.github.io/neural-networks-3

[[Activation Functions]]

Data Preprocessing
- [[Data Normalization]]
- Center data:
	- Subtract the mean image ((32x32x3) array)
	- Subtract per-channel mean (3 numbers)
		- subtracting the mean across every individual _feature_ in the data
- PCA and Whitening
	- [[PCA]]
	- [[Singular Value Decomposition (SVD)]]
	- To decorrelate the data, we project the original (but zero-centered) data into the eigenbasis
	- Whitening
		- takes the data in the eigenbasis and divides every dimension by the eigenvalue to normalize the scale
	- Example with CIFAR-10
- Data leak
	- preprocessing statistics must only be computed on the training data, and then applied to the validation / test data

[[Weight Initialization]]

[[Regularization]]
- L2
	- heavily penalizing peaky weight vectors and preferring diffuse weight vectors
- Max norm constraints
	- Similar to [[Gradient Clipping]]

Loss functions
- [[Cross Entropy Loss (CEL)]]
- Problem: Large number of classes
	- Hierarchical Softmax
- Attribute classification
	- multi-label classifier
	- [[Classification]]
- Regression
	- L2 loss is much harder to optimize than a more stable loss such as Softmax
- Structured prediction
	- labels can be arbitrary structures such as graphs, trees, or other complex objects



# 6. Training Neural Networks