
https://www.notion.so/64928a3a24aa4d8d8b290005e5afec40

# External Links

Учебник по машинному обучению
Яндекс
https://education.yandex.ru/handbook/ml

# Timeline

- 13.12.2023 - 14.12.2023
- 31.08.2024

# 2. Классический ML

# 2.1 Линейные модели

Что делать если признаки категориальные?
- one-hot encoding
- n - number of categories
- n-1 new columns

Feature engineering
- Дополнительные признаки, являющиеся сложными функциями от исходных

Интерпретируемость линейных моделей
- Плюс
- Нужно принимать во внимание Feature engineering

Линейная зависимость между признаками
- Модель может не сойтись
- Регуляризация

## Линейная регрессия

[[Linear Regression]]

Сведение к задаче оптимизации
[[Least Squares]]

Функция потерь
- loss function
- гладкая функция потерь – это хорошо, а кусочно постоянная – просто ужасно

Функционал
- Функция потерь - функционал
- Функционал принимает на вход функцию (в данном случае это наша модель)

Функции потерь
- MSE
	- Mean Squared Error
	- Среднеквадратичное отклонение
	- МНК?
	- Normal noise
- MAE
	- Более устойчив к выбросам
- MAPE


### МНК - Точный аналитический метод

[[Covariance Matrix]]
[[Singular Value Decomposition (SVD)]]

Геометрический подход

Почему линейно-зависимые столбцы в матрице $Х$ приводят к не полному рангу в матрице $X^TX$ ?
Ранги этих матриц равны, но почему?

Обусловленность
- Плохо-обусловленная матрица, что это значит?
- эллипсоиды уровня функции потерь
- ru.wikipedia.org/wiki/Число_обусловленности
- TODO

### МНК - Приближенный численный метод

Минимизируемый функционал является гладким и выпуклым
- Как это доказать?

Градиентный спуск

Стохастический градиентный спуск
- матожидание оценки градиента на батче равно самому градиенту

стратегии отбора объектов
- чаще брать объекты, на которых ошибка больше.

LARS


## Регуляризация

[[Regularization]]

Единственность решения
- В случае если среди столбцов есть линейно зависимые, вектор весов может быть любой длинны, так как найдется вектор весов который будет давай ноль при умножении на любой элемент из выборки.
- Прибавляем вектор весов выше к векторы решения - получаем бесконечное множество различных решений
- Решение может быть сколько угодно большое по модулю.
- В случае линейной независимости столбцов есть только единственное решение?

Large weight values and overfitting
- Почему большие веса матрицы W это плохо?
- Малые погрешности признаков сильно возрастают при предсказании ответа

Система линейных уравнений
- Что означает решить систему линейных уравнений?
- Что означает если есть решение для системы где в правой части стоит нулевой вектор?
- TODO

Причины использовать регуляризацию
- Борьба с коллинеарными признаками и вырожденной матрицей весов
- Переобучение

Свойства
Уменьшает дисперсию, но решение становится смещенным (увеличивается байес)

L2 реуляризация
- ridge regression

L1 регуляризация
- Разряживание весов
- Обнуление определенных признаков

## Логистическая регрессия

[[Logistic Regression]]

Почему не решать как задачу регрессии?
- [[MSE for classification task]]
- MSE лосс почти не штрафует за объекты которые лежат близко к разделяющей плоскости, но не с той стороны

Логистическая регрессия
*Ещё один интересный метод появляется из желания посмотреть на классификацию как на задачу предсказания вероятностей.*

## Многоклассовая классификация

[[Classification]]

Один против всех (one-versus-all)
- Недостаток
	- несколько моделей обучаются на датасетах с разным распределением, выходы моделей могут иметь разные масштабы.

Все против всех (all-versus-all)
- $С_k^2$ - классификаторов
- алгоритмы могут не прийти к единому мнению (не будет класса который наберет максимальное количество голосов)

Sigmoin → Softmax
[[Cross Entropy Loss (CEL)]]

Линейный слой
one-versus-all + Softmax


## Масштабируемость

[[Scalability]]

SGD позволяет обучению хорошо масштабироваться по числу объектов

Как масштабироваться в случае большого числа признаков?
- Примеры когда это необходимо
	- мешок слов
	- tf-idf
- Решение
	- разряженное кодирование
	- hashing trick
	- vowpal wabbit
	- шардированная хеш-таблица


# 3. Оценка качества

# 3.1 Метрики


иерархия метрик

offline и online метрики
Online метрики вычисляются по данным, собираемым с работающей системы

[[Metrics. Classification.]]

## Классификация

Confusion Matrix
- на матрицах нет отношения порядка

Что же всё-таки важнее уменьшить: FP или FN?

Precision and Recall
- Поэтому в случае ассиметрии классов, можно использовать метрики, которые не учитывают TN и ориентируются на TP
- Но нужно правильно выбрать какой из двух классов мы хотим (обычно меньший)

ROC AUC
- [[ROC AUC]]
- Учитываем ошибки на обоих классах
- В каких случаях лучше отдать предпочтение этой метрике?
	- Таким образом, в любой задаче, где нам важна не метка сама по себе, а правильный порядок на объектах, имеет смысл применять AUC.
- Метрика ранжирования?
	- Контрпример

Как оптимизировать метрики классификации?
- Как оптимизировать precision и recall, их нельзя использовать напрямую в функции потерь.
- BCEWithLogitsLoss

Как максимизировать метрику AUC
- Переход к новой задаче, число правильно упорядоченных пар.
- Нужно построить датасет со всеми возможными парами?

## Многоклассовая классификация

Усреднение матрицы ошибок
- микроусреднение
- макроусреднение
- Порядок усреднения влияет на результат в случае дисбаланса классов.

TN для многоклассовой классификации
- Q: Можно ли каким-либо образом ввести величину TN для многоклассовой классификации? Вопрос в том, учитывать ли при этом ошибки на других классах, в случае ошибки на другом классе когда оба и предскание и таргет это другой класс, можно записать TN?

## Регрессия

Целочисленные значения
- Если важен целочисленный результат то нужно оценивать после округления.

MSE
- проблема если в данных присутствуют выбросы
RMSE
- чтобы показатель эффективности MSE имел размерность исходных
MAE
- Менее чувствительна к выбросам

MSE неограничен сверху
- Coefficient of determination

Coefficient of determination
- $R^2$
- https://en.wikipedia.org/wiki/Coefficient_of_determination
- https://chatgpt.com/c/3ab0cf4d-efb3-4bf8-ada0-32b28387a000

Относительные ошибки на таргетах
- Разные таргеты
- При этом есть class imbalance у таргетов

MAPE (mean absolute percentage error)
SMAPE
относительные ошибки

Детекция
- MAE плохая регрессионная метрика для задачи детекции, поэтому используем IOU loss.
- Мы также могли бы использовать MAPE, и считать ошибки относительными площадь бокса.
- [[Metrics. SS and OD]]

# 4. Вероятностные модели


## 4.1 Вероятностный подход в ML

вероятностные модели
- подбор параметров модели с помощью минимизации функции потерь соответствует их подбору методом максимального правдоподобия
- [[MLE]]

generalized linear model (GLM)
- генерализация [[Logistic Regression]]

генеративный подход к классификации
- [[Generative Models]]

байесовской подход оценивания параметров
- трудно осуществим вычислительно, однако обладает большей теоретической стройностью

---

Случайность как источник несовершенства модели
- Аддитивный шум
- Выбор функции потерь соответствуем выбору распределения шума.

Моделирование шума различными распределениями
- [[Probability Distribution]]
- [[Exponential Distribution]]
- В порядке устойчивости к шуму
	- [[Normal Distribution]]
	- Laplace Distribution
	- Распределение Коши

Условное распределение на таргет
- Задача регрессии
- нормальный аддитивный шум

Более сложные вероятностные модели
- [[Probabilistic Graphical Model (PGM)]]

Предсказание в вероятностных моделях
- Когда мы делаем предсказание получаем y не точно, а в виде распределения.
- Если нужно точечное предсказание, то можно вернуть матожидание или медиану или моду.

Условное распределение на таргет, дискретный случай
- Задача классификации
	- [[Logistic Regression]]
	- [[Bernoulli Distribution]]
- **Недостаток / Предостережение**
	- Неполноценность подхода
	- Для подбора параметров используем не эмпирические вероятности, а только лишь метки классов из обучающего датасета
	- [[Probability Calibration]]


## 4.4. Как оценивать вероятности

[[Probability Calibration]]

overconfident
- Слишком уверенный (overconfident) классификатор
- Такое случается с сильными классификаторыми (например, нейросетями)

underconfident
- если мы слишком много обращаем внимания на трудные для классификации объекты на границе классов (как, скажем, в SVM)

логистическая регрессия действительно корректно предсказывает вероятности?

калибровочные кривые


## 4.6 Байесовский подход к оцениванию

Уверенность модели как дисперсия распределения ее параметров.

Вывод формулы [[Beta Distribution]]?
